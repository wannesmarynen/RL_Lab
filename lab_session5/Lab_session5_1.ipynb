{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Lab exercise is to get your hands dirty with some code. <br> It's important you understand the concepts as they'll be important in Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "In linear regression, the relationships are modeled using linear functions whose unknown model parameters are estimated from the data. <br> We'll play around with a popular dataset of wine. <br> In dataset based on multiple features you'll determine the quality of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('winequality-red.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how it looks actually, other popular way to do is calling the head() function. Please refer to pandas for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes dataset can be too huge to display, the shape comes in handy to check how your dataset looks, <br> in current example there are 1599 rows and 12 columns. <br> When working with image dataset the shape maybe in channels like RGB and number of images or 1 channel if it's black and white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with stastical problems describe can give you quick insights. (here it's just to show you some functionalities of pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "real world data is not as clean as this one, **ALWAYS KNOW YOUR DATA** . We check here just in case if there are null values that we may have to remove or fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates','alcohol']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining your data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[features].values\n",
    "y = dataset['quality'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would want to see the distribution of data so we know how imbalanced it is. you can read a lot about imbalance in detail. **It's good and bad ;)** Here we we'll contine playing with this imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.tight_layout()\n",
    "sns.distplot(dataset['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just plot how these 3 features varry for different classes. If you are a wine lover you'll probably know this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship = sns.pairplot(dataset, vars=['fixed acidity','volatile acidity','citric acid'], hue='quality')\n",
    "plt.show(relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop and think why do we have train and test set. If you don't know contact any of the teaching assistant to explain you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINALLY** <br> in this example we just used default parameters. you can have fun with them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from just estimating a function linear regression has lot many uses. It's one of the favorate tools used in reporting. We are just trying to explain the relation of a wine with different features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(regressor.coef_, features, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df1 = df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how you performed shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will you be able to explain the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.plot(kind='bar',figsize=(10,8))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we report common matrices i.e how close we can predict to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "You can choose to read more about them here (https://en.wikipedia.org/wiki/Decision_tree) but in short they are like flowchart where you get the final class based on features. Decisions and their possible consequences are because of your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop('quality',axis=1)\n",
    "y = dataset['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfTre = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clfTre.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "utfall = np.count_nonzero(clfTre.predict(X_test) == y_test)\n",
    "print(\"The decision tree predicts the test data in\", utfall/(len(X_test))*100 , \"% of the cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we performing better or worst compared to Linear regression? If worst, what can we do? Think about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Random forests or random decision forests are an ensemble method. They are a form of decision tree, except they construct multitude of decision trees at training time and output the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "utfall = np.count_nonzero(rf.predict(X_test) == y_test)\n",
    "print(\"The decision tree predicts the test data in\", utfall/(len(X_test))*100 , \"% of the cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "Multilayer perceptron are type of neuralnets. A single layer without activation function behaves quiet closely like linear regression.\n",
    "I'm sure you guys had fun uptill this point. <br>\n",
    "For upcoming DRL classes it's very important that you develop a good intuition for MLP, CNNs. <br>\n",
    "We want you to run this code and compare with classical algorithms we used previously. \n",
    "Do notice what, how it's learning and since you know your dataset what more/less can be done? <br>\n",
    "Don't forget **Always know your data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 6)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = self.fc2(X)\n",
    "        X = self.fc3(X)\n",
    "        X = self.softmax(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['quality'] = str(dataset['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = np.unique(dataset['quality'].values)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "labels = le.transform(dataset['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(dataset[features].values,\n",
    "                                                    labels, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = Variable(torch.Tensor(train_X).float())\n",
    "test_X = Variable(torch.Tensor(test_X).float())\n",
    "train_y = Variable(torch.Tensor(train_y).long())\n",
    "test_y = Variable(torch.Tensor(test_y).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()# cross entropy loss\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = net(train_X)\n",
    "    loss = criterion(out, train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('number of epoch', epoch, 'loss', loss.data)\n",
    "\n",
    "predict_out = net(test_X)\n",
    "_, predict_y = torch.max(predict_out, 1)\n",
    "\n",
    "print ('prediction accuracy', accuracy_score(test_y.data, predict_y.data))\n",
    "\n",
    "print ('macro precision', precision_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro precision', precision_score(test_y.data, predict_y.data, average='micro'))\n",
    "print ('macro recall', recall_score(test_y.data, predict_y.data, average='macro'))\n",
    "print ('micro recall', recall_score(test_y.data, predict_y.data, average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
